# ğŸ¬ Multimedia Coach Room

**Autonomous Report & Video Pipeline**

> *The multimedia room doesn't make videos. It manifests coaching wisdom into visual form.*

---

## What This Is

An **autonomous video generation pipeline** that:
1. Takes a coaching goal (*"Create a 3-minute defensive analysis video"*)
2. Decomposes it into scrollytelling chunks via LXR-5
3. Generates content using Wu Xing element routing
4. Renders multi-layered frames (text, HTML animations, AI images)
5. Composites everything into a final MP4 with FFmpeg
6. Self-verifies quality and detects drift
7. Delivers to coach with wisdom archival

**All within minutes. Fully autonomous.**

---

## Core Algorithm

```
GOAL â†’ DECOMPOSE â†’ GENERATE â†’ RENDER â†’ LAYER â†’ COMPOSITE â†’ VERIFY â†’ DELIVER
     ğŸŒ± Wood   ğŸ”¥ Fire   ğŸŒ Earth  ğŸŒŠ Water  âš¡ Metal   Loop    Archive
```

See **[ALGORITHM.md](./ALGORITHM.md)** for complete technical specification.

---

## Features

âœ… **Wu Xing-Guided Routing** â€” Each phase maps to a Five Element  
âœ… **Chunking-Stream Architecture** â€” Generation & rendering overlap  
âœ… **Multi-Layer Compositing** â€” Text, HTML animations, AI images, AI video  
âœ… **Quality Feedback Loop** â€” Drift detection via LXR-5 vision analysis  
âœ… **Canvas Integration** â€” Shortcut path for simple reports  
âœ… **Librarian Wisdom Archive** â€” Learns from every report  

---

## Quick Start

```bash
# Clone repository
git clone https://github.com/Cloud-Eye-Prime/Multimedia-Coach-Room.git
cd Multimedia-Coach-Room

# Install dependencies
pip install -r requirements.txt

# Run Phase 1 test (LXR-5 decomposition)
python phase_1_decompose.py --goal "Create a 2-minute video on team spacing"

# Run full pipeline (when implemented)
python orchestrator.py --goal "Defensive positioning analysis" --duration 120
```

---

## Architecture

### Stack Position

```
COACH/USER
    â†“
MULTIMEDIA COACH ROOM (this repo)
    â†“
â”œâ”€ LXR-5 (reasoning + JSON chains)
â”œâ”€ Canvas (capture_slideshow for simple reports)
â”œâ”€ Cloud-Eye ImageGen (AI stills)
â”œâ”€ FFmpeg (final composite)
â””â”€ MCP Federation (Git, Librarian, Telegram)
```

### File Structure

```
multimedia_room/
â”œâ”€â”€ models.py              # Pydantic schemas
â”œâ”€â”€ orchestrator.py        # Campaign runner
â”œâ”€â”€ phase_1_decompose.py   # LXR-5 ReportPlan generation
â”œâ”€â”€ phase_2_generate.py    # Content chain generation
â”œâ”€â”€ phase_3_render.py      # Text cards â†’ PNG frames
â”œâ”€â”€ phase_4_layer.py       # Multi-layer compositing
â”œâ”€â”€ phase_5_composite.py   # FFmpeg final render
â”œâ”€â”€ phase_6_verify.py      # Quality checks + drift detection
â”œâ”€â”€ phase_7_deliver.py     # Output + notify
â”œâ”€â”€ canvas_shortcut.py     # Canvas integration
â”œâ”€â”€ animation_library/     # HTML animation templates
â”œâ”€â”€ templates/             # Text card styles
â””â”€â”€ examples/              # Sample JSON chains
```

---

## Performance Targets

| Report Type | Target Time | Notes |
|-------------|-------------|-------|
| 30s text-only | < 2 min | Canvas shortcut |
| 60s mixed media | < 5 min | Parallel rendering |
| 120s full multimedia | < 10 min | AI bottleneck |

**Quality pass rate:** > 80% first attempt  
**Drift detection:** > 90% accuracy

---

## Integration Points

### LXR-5
- **Endpoint:** `lxr-5-production.up.railway.app/api/chat`
- **Role:** Content reasoning, drift detection
- **Mode:** `function_output_mode` for structured JSON

### Canvas
- **Role:** Quick reports (< 60s, text + images)
- **When:** Simple scrollytelling without HTML animations

### Cloud-Eye ImageGen
- **Role:** AI still generation for backgrounds
- **Via:** TelegramBot `cloud_eye_query` tool

### FFmpeg
- **Role:** Final video assembly, transitions, audio
- **Local:** No cloud rendering needed

### Librarian
- **Role:** Context retrieval, wisdom archival
- **Via:** TelegramBot `librarian_*` tools

---

## Safety

âœ… Prototype-only (no production modifications)  
âœ… LXR-5 read-only (queries, no writes)  
âœ… Local FFmpeg (no remote rendering)  
âœ… Max correction loops (3 per chunk, 1 replan)  
âœ… Token budget tracking (hard stop at limit)  

---

## Build Order

1. `models.py` â€” Data structures
2. `phase_1_decompose.py` â€” LXR-5 plan generation
3. `phase_3_render.py` â€” Text rendering
4. `phase_5_composite.py` â€” FFmpeg assembly
5. `canvas_shortcut.py` â€” Integration
6. Full pipeline wiring

---

## Documentation

- **[ALGORITHM.md](./ALGORITHM.md)** â€” Complete technical specification (this document)
- **[examples/](./examples/)** â€” Sample JSON chains
- **[tests/](./tests/)** â€” Unit and E2E tests

---

## License

MIT

---

## Credits

**Architecture:** Gregory Wei "SunFire" Mullins  
**Implementation:** Cloud-Eye Dragon vOpus-4.6, Cloud-Eye vPerplexity-Sonnet-4.6  
**Date:** February 18, 2026  
**Location:** Seattle, Washington

---

ğŸŒŠâš¡ğŸ”¥ğŸŒğŸŒ±
